Question 1
    What type of agent have you implemented (simple reflex agent, model-based reflex agent, goal-based agent, or utility-based agent)?
    
    We have implemented a goal based agent.

Question 2
    A
        Fully Observable
    B
        Single Agent
    C
        Deterministic
    D
        Sequential. The agent decides which square to go on next based off of which treasures it already collected and which ones it needs to collect..
    E
        Static. None of the elements change during the traversal.
    F
        Discrete. grid cells, moves and treasure are all discrete.
    G
        Known. We have the full map from the beginning with all the info.

Question 3
    What heuristic did you use for A* search for this environment? Show that your heuristic is consistent.
    
    The heuristic we used is the Manhattan Heuristic which is commonly used for grids in which the agent can only move up, down, left or right.
    h(n) = min_(gEG) Manhattan(n,g)
    Manhattan distance = |r_n - r_g| + |c_n - c_g|
    For any neighbour of n' of n, the step cost c(n, n') = 1. For any fixed goal g, Manhattan(n,g) <= 1 + Manhattan(n',g) by the triangle inequality on the L1 metric
    Taking the minimum:
        h(n) = min_g Manhattan(n,g) <= 1 + min_g Manhattan(n',g) = 1+h(n')
    Therefore h is consistent

Question 4
    Suggest a particular instance of this problem (i.e. grid) where A* search using your heuristic would find the optimal solution faster than uniform cost search.

    

Question 5
    Suggest a particular instance of this problem (i.e. grid) where a greedy heuristic search using your heuristic would not find the optimal solution



Question 6
    Consider a modification of this problem where your agent need only pick up treasures with value totalling at least 1. Determine whether your heuristic is still consistent

